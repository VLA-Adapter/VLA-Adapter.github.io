# VLA-Adapter

<p align="center">
    <img src="https://huggingface.co/datasets/VLA-Adapter/Figures/resolve/main/Logo.png" width="800"/>
<p>

This is the repository that contains source code for the [VLA-Adapter Project Page](https://vla-adapter.github.io/).

If you find Nerfies useful for your work please cite:
```
@article{Wang2025VLAAdapter,
  author = {Wang, Yihao and Ding, Pengxiang and Li, Lingxiao and Cui, Can and Ge, Zirui and Tong, Xinyang and Song, Wenxuan and Zhao, Han and Zhao, Wei and Hou, Pengxu and Huang, Siteng and Tang, Yifan and Wang, Wenhui and Zhang, Ru and Liu, Jianyi and Wang, Donglin},
  title = {VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model},
  journal = {ArXiv},
  year = {2025}
}

```

# Website License
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
